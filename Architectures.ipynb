{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHFXBawWAEhU"
      },
      "source": [
        "# **Neural Networks' Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "P-EhU7of-821"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.python.ops import rnn, rnn_cell\n",
        "\n",
        "import seaborn as sns\n",
        "import os\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import legacy\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.python.ops import rnn, rnn_cell\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMbyJsYwAQmC",
        "outputId": "4ae99d46-b857-48a7-ec33-a1028d8d339e"
      },
      "outputs": [],
      "source": [
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWmr4us5ASiV"
      },
      "source": [
        "## Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LfkcbZxBAVPJ"
      },
      "outputs": [],
      "source": [
        "def build_rnn_model(input_shape, num_classes, l2_lambda, n_hidden_units):\n",
        "\n",
        "    # Number of features and timesteps\n",
        "    num_features = input_shape[1]\n",
        "    timesteps = input_shape[0]\n",
        "\n",
        "\n",
        "    # Build the model\n",
        "    model = models.Sequential([\n",
        "\n",
        "        layers.LSTM(n_hidden_units, return_sequences=True, input_shape=(timesteps, num_features),\n",
        "            dropout=0.25, recurrent_dropout=0.25,\n",
        "            kernel_regularizer=regularizers.l2(l2_lambda)),\n",
        "\n",
        "        layers.LSTM(n_hidden_units, dropout=0.25, recurrent_dropout=0.25,\n",
        "                    kernel_regularizer=regularizers.l2(l2_lambda)),\n",
        "\n",
        "        layers.Dense(num_classes, activation='softmax',\n",
        "                     kernel_regularizer=regularizers.l2(l2_lambda))\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oxj3C6FMLiCQ"
      },
      "outputs": [],
      "source": [
        "def build_bd_rnn_model(input_shape, num_classes, l2_lambda, n_hidden_units):\n",
        "    # Number of features and timesteps\n",
        "    num_features = input_shape[1]\n",
        "    timesteps = input_shape[0]\n",
        "\n",
        "    # Build the model\n",
        "    model = models.Sequential([\n",
        "        # First LSTM layer wrapped in Bidirectional\n",
        "        layers.Bidirectional(\n",
        "            layers.LSTM(n_hidden_units, return_sequences=True, dropout=0.25, recurrent_dropout=0.25,\n",
        "                        kernel_regularizer=regularizers.l2(l2_lambda)),\n",
        "            input_shape=(timesteps, num_features)\n",
        "        ),\n",
        "\n",
        "        # Second LSTM layer wrapped in Bidirectional\n",
        "        layers.Bidirectional(\n",
        "            layers.LSTM(n_hidden_units, dropout=0.25, recurrent_dropout=0.25,\n",
        "                        kernel_regularizer=regularizers.l2(l2_lambda))\n",
        "        ),\n",
        "\n",
        "        # Dense layer for classification\n",
        "        layers.Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(l2_lambda))\n",
        "    ])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKIr6KvDAaey"
      },
      "source": [
        "## Multilayer Percepton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pQVR7jBBAcWj"
      },
      "outputs": [],
      "source": [
        "def build_mlp_model(input_shape, num_classes, l2_lambda, n_hidden_units):\n",
        "    # Extração de num_features e timesteps do input_shape\n",
        "    timesteps= input_shape[0] #751\n",
        "    num_features = input_shape[1] #mfcc\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    # The input layer is defined with the correct number of characteristics\n",
        "    # The flatter layer transforms the 2D entrance (timesteps x num_features) in a 1D entrance\n",
        "    model.add(layers.Flatten(input_shape=(timesteps, num_features)))\n",
        "\n",
        "    # First hidden layer\n",
        "    model.add(layers.Dense(n_hidden_units, activation='relu', kernel_regularizer=regularizers.l2(l2_lambda)))\n",
        "    model.add(layers.Dropout(0.1))  # Dropout layer for regularization\n",
        "\n",
        "    # Second hidden layer\n",
        "    model.add(layers.Dense(n_hidden_units, activation='relu', kernel_regularizer=regularizers.l2(l2_lambda)))\n",
        "    model.add(layers.Dropout(0.1))\n",
        "\n",
        "    # Third hidden layer\n",
        "    model.add(layers.Dense(n_hidden_units, activation='relu', kernel_regularizer=regularizers.l2(l2_lambda)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
