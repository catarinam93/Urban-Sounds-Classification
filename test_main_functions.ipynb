{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import legacy\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')\n",
    "%run Architectures.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear Previous Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for a single iteration of the cross validation\n",
    "##### fold1 - test\n",
    "##### fold2 and fold3 - validation\n",
    "##### fold3 - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(nn_type, mfcc, n_epochs, batch_size, learning_rate, momentum, l2_lambda, n_hidden_units):\n",
    "    \n",
    "    i = 1 #fold1 used for test\n",
    "\n",
    "    # Define test set paths\n",
    "    X_test_path = 'UrbanSound8K/audio/fold'+str(i)+'_4sec_mfccs_13/3D_array.npy'\n",
    "    Y_test_path = 'UrbanSound8K/audio/fold'+str(i)+'_label/3D_array.npy'\n",
    "\n",
    "    X_val_path1 = 'UrbanSound8K/audio/fold'+str((i+1-1) % 10 + 1)+f'_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "    Y_val_path1 = 'UrbanSound8K/audio/fold'+str((i+1-1) % 10 + 1)+'_label/3D_array.npy'\n",
    "    X_val_path2 = 'UrbanSound8K/audio/fold'+str((i+2-1) % 10 + 1)+f'_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "    Y_val_path2 = 'UrbanSound8K/audio/fold'+str((i+2-1) % 10 + 1)+'_label/3D_array.npy'\n",
    "\n",
    "    # Combine the validation paths\n",
    "    X_val_paths = [X_val_path1, X_val_path2]\n",
    "    Y_val_paths = [Y_val_path1, Y_val_path2]\n",
    "\n",
    "    # # Define training set paths (all remaining folds)\n",
    "    X_train_paths = ['UrbanSound8K/audio/fold'+str((j-1) % 10 + 1)+f'_4sec_mfccs_{mfcc}/3D_array.npy' for j in range(i+3, i+10)]\n",
    "    Y_train_paths = ['UrbanSound8K/audio/fold'+str((j-1) % 10 + 1)+'_label/3D_array.npy' for j in range(i+3, i+10)]\n",
    "\n",
    "    # Define test set paths\n",
    "    X_test_path = f'UrbanSound8K/audio/fold{i}_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "    Y_test_path = f'UrbanSound8K/audio/fold{i}_label/3D_array.npy'\n",
    "\n",
    "    # Define validation set paths (wrapping around if i+2 > 10)\n",
    "    X_val_path1 = f'UrbanSound8K/audio/fold{((i+1-1) % 10 + 1)}_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "    Y_val_path1 = f'UrbanSound8K/audio/fold{((i+1-1) % 10 + 1)}_label/3D_array.npy'\n",
    "    X_val_path2 = f'UrbanSound8K/audio/fold{((i+2-1) % 10 + 1)}_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "    Y_val_path2 = f'UrbanSound8K/audio/fold{((i+2-1) % 10 + 1)}_label/3D_array.npy'\n",
    "\n",
    "    # Combine the validation paths\n",
    "    X_val_paths = [X_val_path1, X_val_path2]\n",
    "    Y_val_paths = [Y_val_path1, Y_val_path2]\n",
    "\n",
    "    # Define training set paths (all remaining folds)\n",
    "    X_train_paths = [f'UrbanSound8K/audio/fold{((j-1) % 10 + 1)}_4sec_mfccs_{mfcc}/3D_array.npy' for j in range(i+3, i+11)]\n",
    "    Y_train_paths = [f'UrbanSound8K/audio/fold{((j-1) % 10 + 1)}_label/3D_array.npy' for j in range(i+3, i+11)]\n",
    "\n",
    "    # Load the datasets from the paths\n",
    "    X_test = np.load(X_test_path)\n",
    "    Y_test = np.load(Y_test_path)\n",
    "\n",
    "\n",
    "    X_val1 = np.load(X_val_path1)\n",
    "    X_val2 = np.load(X_val_path2)\n",
    "    Y_val1 = np.load(Y_val_path1)\n",
    "    Y_val2 = np.load(Y_val_path2)\n",
    "\n",
    "    X_train = [np.load(path) for path in X_train_paths]\n",
    "    Y_train = [np.load(path) for path in Y_train_paths]\n",
    "\n",
    "\n",
    "    # Find the minimum size among all folds\n",
    "    min_size = min([X_test.shape[0], X_val1.shape[0], X_val2.shape[0]] + [x.shape[0] for x in X_train])\n",
    "\n",
    "    # Resize the data of each fold to the minimum size\n",
    "    X_test_resized = X_test[:min_size]\n",
    "    Y_test_resized = Y_test[:min_size]\n",
    "\n",
    "    X_val1_resized = X_val1[:min_size]\n",
    "    Y_val1_resized = Y_val1[:min_size]\n",
    "\n",
    "    X_val2_resized = X_val2[:min_size]\n",
    "    Y_val2_resized = Y_val2[:min_size]\n",
    "\n",
    "    X_train_resized = [x[:min_size] for x in X_train]\n",
    "    Y_train_resized = [y[:min_size] for y in Y_train]\n",
    "\n",
    "\n",
    "    # Combine the validation sets\n",
    "    X_test = X_test_resized\n",
    "    Y_test = Y_test_resized\n",
    "    X_val = np.concatenate((X_val1_resized, X_val2_resized), axis=2)\n",
    "    Y_val = np.concatenate((Y_val1_resized, Y_val2_resized), axis=2)\n",
    "    X_train = np.concatenate((X_train_resized[0], X_train_resized[1], X_train_resized[2], X_train_resized[3], X_train_resized[4], X_train_resized[5], X_train_resized[6]), axis=2)\n",
    "    Y_train = np.concatenate((Y_train_resized[0], Y_train_resized[1], Y_train_resized[2], Y_train_resized[3], Y_train_resized[4], Y_train_resized[5], Y_train_resized[6]), axis=2)\n",
    "\n",
    "    X_test = X_test.transpose(2,1,0)\n",
    "    Y_test = Y_test.transpose(2,1,0)\n",
    "    X_val = X_val.transpose(2,1,0)\n",
    "    Y_val = Y_val.transpose(2,1,0)\n",
    "    X_train = X_train.transpose(2,1,0)\n",
    "    Y_train = Y_train.transpose(2,1,0)\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Clear Previous Sessions\n",
    "    clear_session()  \n",
    "\n",
    "\n",
    "    # Call de neural network\n",
    "    input_shape = (751, mfcc)\n",
    "    num_classes = 10\n",
    "\n",
    "\n",
    "    #Neural Network Initialization\n",
    "    if nn_type == \"mlp\":\n",
    "        model = build_mlp_model(input_shape, num_classes, l2_lambda, n_hidden_units)\n",
    "\n",
    "    elif nn_type == \"rnn\":\n",
    "        model = build_rnn_model(input_shape, num_classes, l2_lambda, n_hidden_units)\n",
    "\n",
    "    else:\n",
    "        print(\"Introduce a valid neural network\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # print The neural network's architecture\n",
    "    model.summary() \n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = legacy.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "    #output layer\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    \n",
    "    Y_train = np.squeeze(Y_train, axis=1)\n",
    "    Y_val = np.squeeze(Y_val, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "\n",
    "        #training dataset\n",
    "        X_train,\n",
    "        Y_train,\n",
    "\n",
    "        epochs=n_epochs,  # Number of epochs\n",
    "        batch_size=batch_size, # Number of samples per batch\n",
    "\n",
    "        #validation dataset\n",
    "        validation_data=(X_val, Y_val)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Y_train_classes = np.squeeze(Y_train).argmax(axis=-1) if Y_train.ndim == 3 else Y_train\n",
    "    Y_val_classes = np.squeeze(Y_val).argmax(axis=-1) if Y_val.ndim == 3 else Y_val\n",
    "\n",
    "    # Generate predictions\n",
    "    Y_pred = model.predict(X_test)  # Predicted probabilities\n",
    "\n",
    "    # Convert predictions to class labels\n",
    "    Y_pred_classes = np.argmax(Y_pred, axis=-1)  # Convert probabilities to class labels\n",
    "\n",
    "    # Flatten the one-hot encoded labels to 1D if they are 3D for Y_test\n",
    "    Y_test_classes = np.squeeze(Y_test).argmax(axis=-1) if Y_test.ndim == 3 else Y_test\n",
    "\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "    conf_matrix = confusion_matrix(Y_test_classes, Y_pred_classes)\n",
    "\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(X_test, np.squeeze(Y_test), verbose=0)\n",
    "    print(f\"Test accuracy for fold {i}:\", scores[1])\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate precision and recall\n",
    "    precision = precision_score(Y_test_classes, Y_pred_classes, average='macro')\n",
    "    recall = recall_score(Y_test_classes, Y_pred_classes, average='macro')\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot training history\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss','test_loss'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    return scores[1], history "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(nn_type, mfcc, n_epochs, batch_size, learning_rate, momentum, l2_lambda, n_hidden_units):\n",
    "   \n",
    "    # General Confusion Matrix\n",
    "    confusion_matrix_accumulated = np.zeros((10, 10))\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(1, 11):\n",
    "\n",
    "        # Define test set paths\n",
    "        X_test_path = 'UrbanSound8K/audio/fold'+str(i)+'_4sec_mfccs_13/3D_array.npy'\n",
    "        Y_test_path = 'UrbanSound8K/audio/fold'+str(i)+'_label/3D_array.npy'\n",
    "\n",
    "        X_val_path1 = 'UrbanSound8K/audio/fold'+str((i+1-1) % 10 + 1)+f'_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "        Y_val_path1 = 'UrbanSound8K/audio/fold'+str((i+1-1) % 10 + 1)+'_label/3D_array.npy'\n",
    "        X_val_path2 = 'UrbanSound8K/audio/fold'+str((i+2-1) % 10 + 1)+f'_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "        Y_val_path2 = 'UrbanSound8K/audio/fold'+str((i+2-1) % 10 + 1)+'_label/3D_array.npy'\n",
    "\n",
    "        # Combine the validation paths\n",
    "        X_val_paths = [X_val_path1, X_val_path2]\n",
    "        Y_val_paths = [Y_val_path1, Y_val_path2]\n",
    "\n",
    "        # # Define training set paths (all remaining folds)\n",
    "        X_train_paths = ['UrbanSound8K/audio/fold'+str((j-1) % 10 + 1)+f'_4sec_mfccs_{mfcc}/3D_array.npy' for j in range(i+3, i+10)]\n",
    "        Y_train_paths = ['UrbanSound8K/audio/fold'+str((j-1) % 10 + 1)+'_label/3D_array.npy' for j in range(i+3, i+10)]\n",
    "\n",
    "        # Define test set paths\n",
    "        X_test_path = f'UrbanSound8K/audio/fold{i}_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "        Y_test_path = f'UrbanSound8K/audio/fold{i}_label/3D_array.npy'\n",
    "\n",
    "        # Define validation set paths (wrapping around if i+2 > 10)\n",
    "        X_val_path1 = f'UrbanSound8K/audio/fold{((i+1-1) % 10 + 1)}_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "        Y_val_path1 = f'UrbanSound8K/audio/fold{((i+1-1) % 10 + 1)}_label/3D_array.npy'\n",
    "        X_val_path2 = f'UrbanSound8K/audio/fold{((i+2-1) % 10 + 1)}_4sec_mfccs_{mfcc}/3D_array.npy'\n",
    "        Y_val_path2 = f'UrbanSound8K/audio/fold{((i+2-1) % 10 + 1)}_label/3D_array.npy'\n",
    "\n",
    "        # Combine the validation paths\n",
    "        X_val_paths = [X_val_path1, X_val_path2]\n",
    "        Y_val_paths = [Y_val_path1, Y_val_path2]\n",
    "\n",
    "        # Define training set paths (all remaining folds)\n",
    "        X_train_paths = [f'UrbanSound8K/audio/fold{((j-1) % 10 + 1)}_4sec_mfccs_{mfcc}/3D_array.npy' for j in range(i+3, i+11)]\n",
    "        Y_train_paths = [f'UrbanSound8K/audio/fold{((j-1) % 10 + 1)}_label/3D_array.npy' for j in range(i+3, i+11)]\n",
    "\n",
    "        # Load the datasets from the paths\n",
    "        X_test = np.load(X_test_path)\n",
    "        Y_test = np.load(Y_test_path)\n",
    "\n",
    "\n",
    "        X_val1 = np.load(X_val_path1)\n",
    "        X_val2 = np.load(X_val_path2)\n",
    "        Y_val1 = np.load(Y_val_path1)\n",
    "        Y_val2 = np.load(Y_val_path2)\n",
    "\n",
    "        X_train = [np.load(path) for path in X_train_paths]\n",
    "        Y_train = [np.load(path) for path in Y_train_paths]\n",
    "\n",
    "        \n",
    "        # Find the minimum size among all folds\n",
    "        min_size = min([X_test.shape[0], X_val1.shape[0], X_val2.shape[0]] + [x.shape[0] for x in X_train])\n",
    "\n",
    "        # Resize the data of each fold to the minimum size\n",
    "        X_test_resized = X_test[:min_size]\n",
    "        Y_test_resized = Y_test[:min_size]\n",
    "\n",
    "        X_val1_resized = X_val1[:min_size]\n",
    "        Y_val1_resized = Y_val1[:min_size]\n",
    "\n",
    "        X_val2_resized = X_val2[:min_size]\n",
    "        Y_val2_resized = Y_val2[:min_size]\n",
    "\n",
    "        X_train_resized = [x[:min_size] for x in X_train]\n",
    "        Y_train_resized = [y[:min_size] for y in Y_train]\n",
    "\n",
    "\n",
    "        # Combine the validation sets\n",
    "        X_test = X_test_resized\n",
    "        Y_test = Y_test_resized\n",
    "        X_val = np.concatenate((X_val1_resized, X_val2_resized), axis=2)\n",
    "        Y_val = np.concatenate((Y_val1_resized, Y_val2_resized), axis=2)\n",
    "        X_train = np.concatenate((X_train_resized[0], X_train_resized[1], X_train_resized[2], X_train_resized[3], X_train_resized[4], X_train_resized[5], X_train_resized[6]), axis=2)\n",
    "        Y_train = np.concatenate((Y_train_resized[0], Y_train_resized[1], Y_train_resized[2], Y_train_resized[3], Y_train_resized[4], Y_train_resized[5], Y_train_resized[6]), axis=2)\n",
    "\n",
    "        X_test = X_test.transpose(2,1,0)\n",
    "        Y_test = Y_test.transpose(2,1,0)\n",
    "        X_val = X_val.transpose(2,1,0)\n",
    "        Y_val = Y_val.transpose(2,1,0)\n",
    "        X_train = X_train.transpose(2,1,0)\n",
    "        Y_train = Y_train.transpose(2,1,0)\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        # Clear Previous Sessions\n",
    "        clear_session()  \n",
    "\n",
    "\n",
    "        # Call de neural network\n",
    "        input_shape = (751, mfcc)\n",
    "        num_classes = 10\n",
    "\n",
    "        #Neural Network Initialization\n",
    "        if nn_type == \"mlp\":\n",
    "            model = build_mlp_model(input_shape, num_classes, l2_lambda, n_hidden_units)\n",
    "\n",
    "        elif nn_type == \"rnn\":\n",
    "            model = build_rnn_model(input_shape, num_classes, l2_lambda, n_hidden_units)\n",
    "\n",
    "        else:\n",
    "            print(\"Introduce a valid neural network\")\n",
    "\n",
    "\n",
    "        # print The neural network's architecture\n",
    "        model.summary() \n",
    "        \n",
    "        optimizer = legacy.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "        #output layer\n",
    "        model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "        #fiz isto pq estava a dar erro e não sei porquê, mas funciona para rnn\n",
    "        Y_train = np.squeeze(Y_train, axis=1)\n",
    "        Y_val = np.squeeze(Y_val, axis=1)\n",
    "\n",
    "\n",
    "        # Compile the model.\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "\n",
    "        history = model.fit(\n",
    "\n",
    "            #training dataset\n",
    "            X_train,\n",
    "            Y_train,\n",
    "\n",
    "            epochs=n_epochs,  # Number of epochs\n",
    "            batch_size=batch_size, # Number of samples per batch\n",
    "\n",
    "            #validation dataset\n",
    "            validation_data=(X_val, Y_val)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "        # Evaluate the model\n",
    "        Y_train_classes = np.squeeze(Y_train).argmax(axis=-1) if Y_train.ndim == 3 else Y_train\n",
    "        Y_val_classes = np.squeeze(Y_val).argmax(axis=-1) if Y_val.ndim == 3 else Y_val\n",
    "\n",
    "        # Generate predictions\n",
    "        Y_pred = model.predict(X_test)  # Predicted probabilities\n",
    "\n",
    "        # Convert predictions to class labels\n",
    "        Y_pred_classes = np.argmax(Y_pred, axis=-1)  # Convert probabilities to class labels\n",
    "\n",
    "        # Flatten the one-hot encoded labels to 1D if they are 3D for Y_test\n",
    "        Y_test_classes = np.squeeze(Y_test).argmax(axis=-1) if Y_test.ndim == 3 else Y_test\n",
    "\n",
    "        # Calculate the confusion matrix\n",
    "        conf_matrix = confusion_matrix(Y_test_classes, Y_pred_classes)\n",
    "        confusion_matrix_accumulated += conf_matrix\n",
    "\n",
    "        # Evaluate the model, ensuring the Y_test used here matches the format expected by the model\n",
    "        scores = model.evaluate(X_test, np.squeeze(Y_test), verbose=0)\n",
    "        print(f\"Test accuracy for fold {i}:\", scores[1])\n",
    "\n",
    "\n",
    "        # Calculate precision and recall\n",
    "        precision = precision_score(Y_test_classes, Y_pred_classes, average='macro')\n",
    "        recall = recall_score(Y_test_classes, Y_pred_classes, average='macro')\n",
    "\n",
    "        print(f\"Precision: {precision}\")\n",
    "        print(f\"Recall: {recall}\")\n",
    "\n",
    "        accuracies.append(scores[1])\n",
    "        print(f\"Test accuracy for fold {i}:\", scores[1])\n",
    "\n",
    "\n",
    "    print(\"General Confusion Matrix:\")\n",
    "    print(confusion_matrix_accumulated)\n",
    "\n",
    "    print(\"Accuracies' Average:\")\n",
    "    print(np.mean(accuracies))\n",
    "\n",
    "    print(\"Standard Deviation of the accuracies:\")\n",
    "    print(np.std(accuracies))\n",
    "\n",
    "    # Bar plot to visualize the accuracies\n",
    "    plt.bar(range(1, 11), accuracies)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy Across Iterations')\n",
    "    plt.show()\n",
    "\n",
    "    # plot training history\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss','test_loss'], loc='upper left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
